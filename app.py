import streamlit as st
import json
import os
from dotenv import load_dotenv

# ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="FAQ RAG ì±—ë´‡", page_icon="ğŸ”‘", layout="wide")

# ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥ ë°›ê¸°
st.sidebar.title("ğŸ” ì„¤ì •")
user_api_key = st.sidebar.text_input(
    "OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
    type="password", 
    placeholder="sk-..."
)
st.sidebar.info("ì…ë ¥í•˜ì‹  API í‚¤ëŠ” ë©”ëª¨ë¦¬ì—ë§Œ ìœ ì§€ë˜ë©° ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 1. ë°ì´í„° ë¡œë“œ ë° ë²¡í„° DB ìƒì„± (API í‚¤ í•„ìš”) ---
@st.cache_resource
def get_vector_db(api_key):
    # API í‚¤ê°€ ì—†ìœ¼ë©´ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
    if not api_key:
        return None, None
        
    file_path = 'faq_chatbot_data.json'
    if not os.path.exists(file_path):
        st.error(f"'{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
        
    with open(file_path, 'r', encoding='utf-8') as f:
        faq_data = json.load(f)
    
    documents = []
    for item in faq_data:
        # ì§€ì‹œì‚¬í•­: ì§ˆë¬¸+ë‹µë³€ ê²°í•© ì„ë² ë”©
        combined_content = f"ì§ˆë¬¸: {item['question']}\në‹µë³€: {item['answer']}"
        doc = Document(
            page_content=combined_content, 
            metadata={"answer": item['answer'], "question": item['question']}
        )
        documents.append(doc)
    
    # ì „ë‹¬ë°›ì€ API í‚¤ë¡œ ì„ë² ë”© ëª¨ë¸ ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
    vector_db = FAISS.from_documents(documents, embeddings)
    return vector_db, faq_data

# --- 2. ë©”ì¸ í™”ë©´ ë¡œì§ ---
def main():
    st.title("ğŸ¢ ì§€ëŠ¥í˜• FAQ ì„¼í„° (RAG)")
    
    # API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ì•ˆë‚´
    if not user_api_key:
        st.warning("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return

    # ë°ì´í„° ë° ë¦¬íŠ¸ë¦¬ë²„ ì¤€ë¹„
    vector_db, raw_faq = get_vector_db(user_api_key)
    if not vector_db:
        return
        
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})

    # UI ë ˆì´ì•„ì›ƒ ë¶„ë¦¬
    st.markdown("---")
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ“‹ FAQ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ íƒ")
        faq_questions = [f["question"] for f in raw_faq]
        selected_faq = st.selectbox("ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["ì„ íƒ ì•ˆ í•¨"] + faq_questions)

    with col2:
        st.subheader("âœï¸ ì§ì ‘ ì§ˆë¬¸ ì…ë ¥ (ì£¼ê´€ì  ì§ˆë¬¸)")
        user_query = st.text_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ë°˜í’ˆ ê¸°ê°„ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")

    # ìµœì¢… ì§ˆë¬¸ ê²°ì • (ì§ì ‘ ì…ë ¥ ìš°ì„ )
    final_query = ""
    if user_query:
        final_query = user_query
    elif selected_faq != "ì„ íƒ ì•ˆ í•¨":
        final_query = selected_faq

    # --- 3. RAG ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ (LCEL) ---
    if final_query:
        st.info(f"**í˜„ì¬ ì§ˆë¬¸:** {final_query}")
        
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, openai_api_key=user_api_key)

        prompt = ChatPromptTemplate.from_template("""
        ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê°ì„¼í„° ìƒë‹´ì›ì…ë‹ˆë‹¤. ì œê³µëœ [FAQ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
        ì •ë³´ê°€ ì—†ë‹¤ë©´ "ì£„ì†¡í•˜ì§€ë§Œ í•´ë‹¹ ë‚´ìš©ì€ ìƒë‹´ì› ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤."ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.

        [FAQ ì •ë³´]
        {context}

        ì§ˆë¬¸: {input}
        ë‹µë³€:
        """)

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            {"context": retriever | format_docs, "input": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

        # ê²°ê³¼ ì¶œë ¥
        with st.spinner('ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                # 1. ë©”ì¸ ë‹µë³€
                response = rag_chain.invoke(final_query)
                st.success("### ğŸ“¢ ìƒë‹´ì› ë‹µë³€")
                st.write(response)

                # 2. ê²€ìƒ‰ ê·¼ê±° í™•ì¸ (ì—ëŸ¬ í•´ê²°: invoke ë©”ì„œë“œ ì‚¬ìš©)
                with st.expander("ğŸ” ê´€ë ¨ FAQ ê²€ìƒ‰ ê·¼ê±° ë°ì´í„°"):
                    relevant_docs = retriever.invoke(final_query)
                    for i, doc in enumerate(relevant_docs):
                        st.markdown(f"**ê´€ë ¨ ì •ë³´ {i+1}**")
                        st.caption(doc.page_content)
            
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€, í˜¹ì€ ê²°ì œ í•œë„ê°€ ì´ˆê³¼ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()

